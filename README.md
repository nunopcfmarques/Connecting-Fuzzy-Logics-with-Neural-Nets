# Connecting Lukasiewicz Logic with Bounded Rectified Linear Unit Networks

This thesis project aims to extract Lukasiewicz formulas from Rectified Linear Unit Networks (ReLU Networks) bounded in input [0,1]^n and output [0, 1]. This is done in the hopes of extracting meaning from the networks.

It contains a solver for this logic, which indicates if the neural network is capable of reaching a certain value.

It also contains a minimizer for this formulas in this logic by minimizing the an approximate finite valued logic formula.